import torch
import numpy as np
import cv2
from PIL import Image
import matplotlib.pyplot as plt
import torch.nn.functional as F
from torchcam.methods import GradCAMpp

class GradCAMPlusPlusProcessor:
    def __init__(self, model, target_layer):
        self.model = model
        self.target_layer = target_layer
        self.gradients = None
        self.activations = None
        self.hook_layers()

    def hook_layers(self):
        def forward_hook(module, input, output):
            self.activations = output

        def backward_hook(module, grad_input, grad_output):
            self.gradients = grad_output[0]

        self.target_layer.register_forward_hook(forward_hook)
        self.target_layer.register_full_backward_hook(backward_hook)

    def compute_grad_cam_plus_plus(self, input_tensor, class_index=None):

        self.model.eval()

        output = self.model(input_tensor)
        if class_index is None:
            class_index = torch.argmax(output, dim=1).item()

        self.model.zero_grad()
        loss = output[:, class_index]
        loss.backward(retain_graph=True)

        gradients = self.gradients
        activations = self.activations

        gradients_power_2 = gradients ** 2
        gradients_power_3 = gradients ** 3
        sum_gradients = torch.sum(gradients, dim=(2, 3), keepdim=True)
        eps = 1e-8  # to avoid division by zero
        alpha = gradients_power_2 / (2 * gradients_power_2 + sum_gradients * gradients_power_3 + eps)
        weights = torch.sum(alpha * F.relu(gradients), dim=(2, 3), keepdim=True)

        cam = torch.sum(weights * activations, dim=1)
        cam = F.relu(cam)

        cam -= cam.min()
        cam /= cam.max() if cam.max() != 0 else cam
        
        # [1, W, H] -> [W, H] ==> [1, 7, 7] -> [7, 7]
        cam = cam.squeeze(0)

        print(f"Grad-CAM++ size: {cam.shape}")
        print(f"Grad-CAM++ resolution: {cam.shape[0]}x{cam.shape[1]} = {cam.shape[0] * cam.shape[1]} pixels")
        
        return cam.detach().cpu().numpy()

    def compute_grad_cam_plus_plus_by_torchcam(self, input_tensor, class_index=None):

        self.model.eval()

        cam_extractor = GradCAMpp(self.model, target_layer=self.target_layer)
        output = self.model(input_tensor)

        if class_index is None:
            class_index = torch.argmax(output, dim=1).item()

        activation_maps = cam_extractor(class_index, output)

        if isinstance(activation_maps, list) and len(activation_maps) > 0:
            activation_map = activation_maps[0].cpu().numpy()
        else:
            raise ValueError("No activation map was generated by torchcam.")

        # Normalize the heatmap to match the format of compute_grad_cam_plus_plus
        activation_map -= activation_map.min()
        if activation_map.max() != 0:
            activation_map /= activation_map.max()

        # [1, W, H] -> [W, H] ==> [1, 7, 7] -> [7, 7]
        activation_map = activation_map.squeeze(0)

        
        return activation_map

    def overlay_cam_on_image(self, image, cam, alpha = 0.5, red_threshold = 0.8, yellow_threshold = 0.5):
        """
            image (PIL.Image): The original input image.
            cam (np.ndarray): The Score-CAM heatmap.
            alpha (float): The transparency factor for the original image overlaying.
            red_threshold (float): The threshold for red areas. Regions with values greater than this will show heatmap in red.
            yellow_threshold (float): The threshold for yellow areas. Regions with values between red and yellow will show heatmap in yellow.
        """
        img = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)

        # Resize heatmap to match original image dimensions
        heatmap = cv2.resize(cam, (img.shape[1], img.shape[0]))

        # Normalize heatmap to [0, 255]
        heatmap = np.maximum(heatmap, 0)
        heatmap = heatmap / heatmap.max() if heatmap.max() != 0 else heatmap
        heatmap = np.uint8(255 * heatmap)

        heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)

        # Create masks for red, yellow and the remaining regions
        red_mask = heatmap[:, :, 0] > (red_threshold * 255)  # Mask for red regions
        yellow_mask = (heatmap[:, :, 0] > (yellow_threshold * 255)) & (heatmap[:, :, 0] <= (red_threshold * 255))  # Mask for yellow regions
        remaining_mask = ~red_mask & ~yellow_mask  # Mask for the remaining areas (less important regions)

        # Apply heatmap to important regions (red and yellow) with `alpha`
        img[red_mask] = cv2.addWeighted(img, alpha, heatmap, 1 - alpha, 0)[red_mask]  # Apply red regions with `alpha`
        img[yellow_mask] = cv2.addWeighted(img, alpha, heatmap, 1 - alpha, 0)[yellow_mask]  # Apply yellow regions with `alpha`

        # Keep the background intact (remaining areas) with `1 - alpha`
        img[remaining_mask] = cv2.addWeighted(img, 1-alpha, heatmap, alpha, 0)[remaining_mask]  # Apply background with `1 - alpha`

        # Convert back from BGR to RGB and numpy array to PIL.Image
        overlayed_image = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))

        return overlayed_image

    def display_and_save_overlay_cam(self, image, overlayed_image, save_path):
        fig, ax = plt.subplots(1, 2, figsize=(10, 5))

        ax[0].imshow(image)
        ax[0].set_title("Original Image")
        ax[0].axis('off')

        ax[1].imshow(overlayed_image)
        ax[1].set_title("Grad-CAM++")
        ax[1].axis('off')

        plt.tight_layout()
        plt.show()

        overlayed_image.save(save_path)
        print(f"Overlayed image saved to {save_path}")